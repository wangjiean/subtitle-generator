"""
è§†é¢‘å­—å¹•æå– & AI æ€»ç»“ Web åº”ç”¨
å¯åŠ¨: python app.py
è®¿é—®: http://localhost:5003
"""

import os
import json
import uuid
import threading
import hashlib
import queue as _queue_mod
import logging
from logging.handlers import RotatingFileHandler
from flask import Flask, request, jsonify, send_from_directory, Response, stream_with_context
import yt_dlp
from google import genai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¥å¿—ç³»ç»Ÿ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

_log_formatter = logging.Formatter(
    '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# æ–‡ä»¶æ—¥å¿—ï¼šä¿ç•™æœ€è¿‘ 5 ä¸ª 2MB æ–‡ä»¶
_file_handler = RotatingFileHandler(
    os.path.join(LOG_DIR, 'zimu.log'),
    maxBytes=2 * 1024 * 1024,
    backupCount=5,
    encoding='utf-8'
)
_file_handler.setFormatter(_log_formatter)
_file_handler.setLevel(logging.DEBUG)

# æ§åˆ¶å°æ—¥å¿—
_console_handler = logging.StreamHandler()
_console_handler.setFormatter(_log_formatter)
_console_handler.setLevel(logging.INFO)

logger = logging.getLogger('zimu')
logger.setLevel(logging.DEBUG)
logger.addHandler(_file_handler)
logger.addHandler(_console_handler)

# Flask/werkzeug æ—¥å¿—ä¹Ÿå†™æ–‡ä»¶
logging.getLogger('werkzeug').addHandler(_file_handler)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# .env æ–‡ä»¶åŠ è½½ï¼ˆè½»é‡ï¼Œä¸è¦†ç›–å·²æœ‰ç¯å¢ƒå˜é‡ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_local_env_file():
    env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
    if not os.path.exists(env_path):
        return
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for raw in f:
                line = raw.strip()
                if not line or line.startswith('#') or '=' not in line:
                    continue
                key, value = line.split('=', 1)
                key, value = key.strip(), value.strip()
                # å»é™¤å¼•å·åŒ…è£¹
                if len(value) >= 2 and value[0] == value[-1] and value[0] in ('"', "'"):
                    value = value[1:-1]
                if key:
                    os.environ[key] = value
    except Exception as e:
        print(f'[env] è¯»å– .env å¤±è´¥: {e}')  # logger not yet initialized


_load_local_env_file()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompt æ¨¡æ¿åŠ è½½ï¼ˆä» prompts.jsonï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_PROMPTS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'prompts.json')
_prompts_cache = {}  # å†…å­˜ç¼“å­˜
_prompts_mtime = 0   # æ–‡ä»¶ä¿®æ”¹æ—¶é—´

def load_prompts():
    """åŠ è½½ prompts.jsonï¼Œæ”¯æŒçƒ­æ›´æ–°ï¼ˆæ–‡ä»¶ä¿®æ”¹åè‡ªåŠ¨é‡æ–°è¯»å–ï¼‰"""
    global _prompts_cache, _prompts_mtime
    try:
        mtime = os.path.getmtime(_PROMPTS_FILE)
        if mtime != _prompts_mtime:
            with open(_PROMPTS_FILE, 'r', encoding='utf-8') as f:
                _prompts_cache = json.load(f)
            _prompts_mtime = mtime
            try:
                logger.info('å·²åŠ è½½ prompts.jsonï¼ˆ%d ä¸ªæ¨¡æ¿ï¼‰', len([k for k in _prompts_cache if not k.startswith('_')]))
            except Exception:
                pass
    except Exception as e:
        try:
            logger.error('è¯»å– prompts.json å¤±è´¥: %s', e)
        except Exception:
            print(f'[prompts] è¯»å– prompts.json å¤±è´¥: {e}')
    return _prompts_cache


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é…ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_ID = "models/gemini-3-flash-preview"


def _load_gemini_api_keys() -> list[str]:
    """æ”¯æŒå¤š API Keyï¼šä¼˜å…ˆç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡å›é€€åˆ°æœ¬åœ°é»˜è®¤ã€‚"""
    env_keys = os.environ.get('GEMINI_API_KEYS', '').strip()
    if env_keys:
        keys = [k.strip() for k in env_keys.split(',') if k.strip()]
        if keys:
            return keys

    env_single = os.environ.get('GEMINI_API_KEY', '').strip()
    if env_single:
        return [env_single]

    return []


GEMINI_API_KEYS = _load_gemini_api_keys()
GEMINI_CLIENTS = [genai.Client(api_key=k) for k in GEMINI_API_KEYS]


def generate_content_with_fallback(contents, model=MODEL_ID):
    """æŒ‰ key é¡ºåºå°è¯•è°ƒç”¨ï¼›é‡åˆ°é…é¢/é™æµ/å¤±æ•ˆ/è¶…æ—¶è‡ªåŠ¨åˆ‡æ¢ä¸‹ä¸€ä¸ª keyã€‚"""
    import time as _time
    if not GEMINI_CLIENTS:
        raise RuntimeError('æœªé…ç½® Gemini API Keyï¼Œè¯·åœ¨ .env ä¸­è®¾ç½® GEMINI_API_KEYS')
    last_error = None
    for idx, client in enumerate(GEMINI_CLIENTS):
        try:
            return client.models.generate_content(
                model=model,
                contents=contents
            )
        except Exception as e:
            last_error = e
            msg = str(e).lower()
            # å¯è‡ªåŠ¨åˆ‡æ¢çš„é”™è¯¯ç±»å‹
            is_switchable = any(x in msg for x in [
                'quota', 'resource_exhausted', '429', 'rate limit', 'too many requests',  # é…é¢/é™æµ
                '401', '403', 'permission', 'invalid',  'api_key_invalid', 'unauthorized',  # Key å¤±æ•ˆ
                'timeout', 'deadline', 'timed out', 'connection',  # ç½‘ç»œé—®é¢˜
                '500', '502', '503', '504', 'internal', 'unavailable',  # æœåŠ¡ç«¯é”™è¯¯
            ])
            if idx < len(GEMINI_CLIENTS) - 1:
                logger.warning(f"[Gemini] key#{idx+1} å¤±è´¥ï¼ˆ{'å¯åˆ‡æ¢' if is_switchable else 'æœªçŸ¥'}ï¼‰ï¼Œå°è¯•ä¸‹ä¸€ä¸ª keyã€‚åŸå› : {e}")
                _time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿé¿å…è¿ç»­æ‰“çˆ†
                continue
            # æœ€åä¸€ä¸ª key ä¹Ÿå¤±è´¥
            logger.error(f"[Gemini] æ‰€æœ‰ {len(GEMINI_CLIENTS)} ä¸ª key å‡å¤±è´¥ã€‚æœ€åé”™è¯¯: {e}")

    raise RuntimeError(f"æ‰€æœ‰ Gemini Key è°ƒç”¨å¤±è´¥: {last_error}")

app = Flask(__name__, static_folder="static")

# æŒä¹…åŒ–å­˜å‚¨ç›®å½•
DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')
PROJECTS_FILE = os.path.join(DATA_DIR, 'projects.json')
TAGS_FILE = os.path.join(DATA_DIR, 'tags.json')
THUMB_CACHE_DIR = os.path.join(DATA_DIR, 'thumb_cache')

# é»˜è®¤æ ‡ç­¾
DEFAULT_TAGS = ['æ”¿æ²»', 'ç§‘æŠ€', 'ç”Ÿæ´»']


def load_tags():
    """åŠ è½½æ ‡ç­¾åˆ—è¡¨"""
    if os.path.exists(TAGS_FILE):
        try:
            with open(TAGS_FILE, 'r', encoding='utf-8') as f:
                tags = json.load(f)
                if isinstance(tags, list) and len(tags) > 0:
                    return tags
        except (json.JSONDecodeError, IOError):
            pass
    return DEFAULT_TAGS[:]


def save_tags(tags):
    """ä¿å­˜æ ‡ç­¾åˆ—è¡¨"""
    os.makedirs(DATA_DIR, exist_ok=True)
    with open(TAGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(tags, f, ensure_ascii=False, indent=2)


def load_projects():
    """ä»ç£ç›˜åŠ è½½æ‰€æœ‰é¡¹ç›®"""
    if os.path.exists(PROJECTS_FILE):
        try:
            with open(PROJECTS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}


def save_projects(projects):
    """å°†æ‰€æœ‰é¡¹ç›®ä¿å­˜åˆ°ç£ç›˜"""
    os.makedirs(DATA_DIR, exist_ok=True)
    with open(PROJECTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(projects, f, ensure_ascii=False, indent=2)


def save_project(project_id, project_data):
    """ä¿å­˜å•ä¸ªé¡¹ç›®"""
    projects = load_projects()
    projects[project_id] = project_data
    save_projects(projects)


def _now_iso():
    import time
    return time.strftime('%Y-%m-%d %H:%M:%S')


def _project_id_from_session_id(session_id: str) -> str:
    if session_id.startswith('session_'):
        return session_id[len('session_'):]
    return ''


def infer_title_from_url(url: str) -> str:
    """åœ¨è¿˜æ²¡æ‹¿åˆ° yt-dlp æ ‡é¢˜å‰ï¼ŒåŸºäº URL ç”Ÿæˆä¸€ä¸ªçŸ­æ ‡é¢˜ã€‚"""
    try:
        from urllib.parse import urlparse, parse_qs
        u = urlparse(url)
        host = (u.hostname or '').lower()
        path = u.path or ''

        # bilibili: /video/BVxxxx
        if 'bilibili.com' in host:
            parts = [p for p in path.split('/') if p]
            if len(parts) >= 2 and parts[0] == 'video' and parts[1].upper().startswith('BV'):
                return f"Bç«™ {parts[1]}"
            return 'Bç«™è§†é¢‘'

        # b23 short link
        if host.endswith('b23.tv'):
            code = path.strip('/').split('/')[0] if path.strip('/') else ''
            return f"Bç«™çŸ­é“¾ {code}" if code else 'Bç«™çŸ­é“¾'

        # youtube
        if 'youtube.com' in host:
            qs = parse_qs(u.query or '')
            vid = (qs.get('v') or [''])[0]
            return f"YouTube {vid}" if vid else 'YouTube è§†é¢‘'
        if host.endswith('youtu.be'):
            vid = path.strip('/').split('/')[0] if path.strip('/') else ''
            return f"YouTube {vid}" if vid else 'YouTube è§†é¢‘'
    except Exception:
        pass
    return 'æœªå‘½åé¡¹ç›®'


def format_upload_date(date_str: str) -> str:
    """å°† yt-dlp çš„ upload_date (YYYYMMDD) è½¬ä¸º YYYY-MM-DDã€‚"""
    if not date_str or not isinstance(date_str, str):
        return ''
    s = date_str.strip()
    if len(s) == 8 and s.isdigit():
        return f"{s[0:4]}-{s[4:6]}-{s[6:8]}"
    return s


def extract_video_meta(info: dict) -> dict:
    """ä» yt-dlp info ä¸­æå–å‰ç«¯éœ€è¦çš„å…ƒæ•°æ®ã€‚"""
    if not isinstance(info, dict):
        return {'title': '', 'uploader': '', 'upload_date': '', 'thumbnail': '',
                'uploader_url': '', 'uploader_avatar': ''}

    title = info.get('title') or ''
    uploader = info.get('uploader') or info.get('channel') or info.get('uploader_id') or ''
    upload_date = format_upload_date(info.get('upload_date') or '')

    # ä½œè€…ä¸»é¡µé“¾æ¥
    uploader_url = info.get('uploader_url') or info.get('channel_url') or ''

    # Bç«™ï¼šé€šè¿‡ uploader_id (mid) æ„é€  space é“¾æ¥
    if not uploader_url:
        webpage_url = info.get('webpage_url') or info.get('original_url') or ''
        mid = info.get('uploader_id') or ''
        if 'bilibili.com' in webpage_url and mid:
            uploader_url = f'https://space.bilibili.com/{mid}'

    # ä½œè€…å¤´åƒ
    uploader_avatar = ''
    # Bç«™ API ä¼šåœ¨ info ä¸­è¿”å› uploader å¤´åƒ
    for key in ('uploader_thumbnail', 'channel_thumbnail', 'avatar'):
        if info.get(key):
            uploader_avatar = info[key]
            break
    # æœ‰äº› yt-dlp ç‰ˆæœ¬æŠŠå¤´åƒæ”¾ thumbnails åˆ—è¡¨ä¸­å¸¦ id='avatar'
    if not uploader_avatar:
        thumbs_list = info.get('thumbnails') or []
        for t in thumbs_list:
            if isinstance(t, dict) and t.get('id') == 'avatar':
                uploader_avatar = t.get('url', '')
                break

    thumb = info.get('thumbnail') or ''
    if not thumb:
        thumbs = info.get('thumbnails')
        if isinstance(thumbs, list) and thumbs:
            cand = thumbs[-1]
            if isinstance(cand, dict):
                thumb = cand.get('url') or ''

    return {
        'title': title,
        'uploader': uploader,
        'upload_date': upload_date,
        'thumbnail': thumb,
        'uploader_url': uploader_url,
        'uploader_avatar': uploader_avatar,
    }


def _thumbnail_cache_path(url: str, ext: str) -> str:
    digest = hashlib.sha1(url.encode('utf-8')).hexdigest()
    return os.path.join(THUMB_CACHE_DIR, f"{digest}.{ext}")


def _download_thumbnail(url: str, referer: str = ''):
    """ä¸‹è½½å°é¢å¹¶è¿”å› (bytes, content_type)ã€‚"""
    import urllib.request

    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8',
    }
    if referer:
        headers['Referer'] = referer

    req = urllib.request.Request(url, headers=headers)
    with urllib.request.urlopen(req, timeout=20) as resp:
        data = resp.read()
        ctype = resp.headers.get('Content-Type', 'image/jpeg').split(';')[0].strip().lower()
    return data, ctype


def _ext_from_content_type(content_type: str) -> str:
    if content_type == 'image/png':
        return 'png'
    if content_type == 'image/webp':
        return 'webp'
    if content_type == 'image/gif':
        return 'gif'
    return 'jpg'


# å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„çŠ¶æ€
tasks = {}
# å­˜å‚¨æ¯ä¸ªä¼šè¯çš„èŠå¤©å†å²ï¼ˆkey: session_idï¼‰
chat_sessions = {}
# Whisper è½¬å½•é”ï¼ˆMLX Metal ä¸æ”¯æŒå¹¶å‘è½¬å½•ï¼Œå¦åˆ™ä¼šå´©æºƒï¼‰
transcribe_lock = threading.Lock()

# â”€â”€ ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ›¿ä»£è£¸çº¿ç¨‹ï¼Œé˜²æ­¢å¹¶å‘å´©æºƒï¼‰ â”€â”€
task_queue = _queue_mod.Queue()


def _worker_loop():
    """ä»é˜Ÿåˆ—ä¸­ä¾æ¬¡å–ä»»åŠ¡æ‰§è¡Œï¼Œä¿è¯ä¸ä¼šåŒæ—¶è·‘å¤šä¸ªä»»åŠ¡ã€‚"""
    while True:
        task_id, url = task_queue.get()
        try:
            process_video_task(task_id, url)
        except Exception as e:
            t = tasks.get(task_id)
            if isinstance(t, dict):
                t['status'] = 'error'
                t['message'] = f'âŒ åå°ä»»åŠ¡å¼‚å¸¸: {e}'
            logger.exception(f'[worker] ä»»åŠ¡ {task_id} å¼‚å¸¸: {e}')
        finally:
            task_queue.task_done()


# å¯åŠ¨ 1 ä¸ª workerï¼ˆä¸²è¡Œæ‰§è¡Œï¼Œé¿å… MLX Metal å¹¶å‘å´©æºƒï¼‰
threading.Thread(target=_worker_loop, daemon=True).start()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å·¥å…·å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_first_url(text: str) -> str:
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–ç¬¬ä¸€ä¸ª http(s) URLï¼ˆå…¼å®¹ã€Œæ ‡é¢˜+é“¾æ¥ã€æ··åˆæ–‡æœ¬ï¼‰ã€‚"""
    import re
    text = text.strip()
    if not text:
        return ''

    # å¸¦åè®®çš„å®Œæ•´ URL
    m = re.search(r'https?://[^\s<>"\'\u3000]+', text, re.IGNORECASE)
    if m:
        return m.group(0).rstrip('.,;!?')

    # ä¸å¸¦åè®®çš„å¸¸è§åŸŸå
    m = re.search(r'(?:b23\.tv|bilibili\.com|youtube\.com|youtu\.be)/[^\s<>"\'\u3000]*', text, re.IGNORECASE)
    if m:
        return 'https://' + m.group(0).rstrip('.,;!?')

    # å¦‚æœè¾“å…¥çœ‹èµ·æ¥æœ¬èº«å°±æ˜¯ä¸ªçŸ­æ–‡æœ¬ä¸”ä¸å«ç©ºæ ¼ï¼Œå½“ä½œ URL å°è¯•
    if ' ' not in text and '.' in text:
        return text

    return ''


def normalize_url(url):
    """è§„èŒƒåŒ–è§†é¢‘ URLï¼Œç¡®ä¿æœ‰æ­£ç¡®çš„åè®®å’ŒåŸŸåå‰ç¼€"""
    import re
    url = url.strip()

    # å»æ‰åè®®å¤´ï¼Œç»Ÿä¸€å¤„ç†
    bare = re.sub(r'^https?://', '', url)

    # Bç«™é“¾æ¥: ç¡®ä¿æœ‰ www. å‰ç¼€ï¼ˆbilibili.com ä¸å¸¦ www ä¼š 403ï¼‰
    if bare.startswith('bilibili.com'):
        bare = 'www.' + bare
    elif bare.startswith('m.bilibili.com'):
        # ç§»åŠ¨ç«¯é“¾æ¥è½¬æ¡Œé¢ç«¯
        bare = 'www.' + bare[2:]

    # ç¡®ä¿æœ‰ https:// å‰ç¼€
    if not bare.startswith(('www.bilibili.com', 'www.youtube.com', 'youtu.be', 'm.youtube.com')):
        # å…¶ä»–é“¾æ¥ï¼Œä¿æŒåŸæ ·åŠ  https
        if not url.startswith('http'):
            url = 'https://' + bare
        return url

    return 'https://' + bare


def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º MM:SS æ ¼å¼"""
    m, s = divmod(int(seconds), 60)
    h, m = divmod(m, 60)
    if h > 0:
        return f"{h:02d}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"


def extract_official_subtitles(url):
    """
    å°è¯•æå–è§†é¢‘çš„å®˜æ–¹å­—å¹•ï¼ˆè‡ªåŠ¨/æ‰‹åŠ¨å­—å¹•ï¼‰ã€‚
    è¿”å› (segments_list, source_type) æˆ– (None, None)
    """
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'skip_download': True,
        'writesubtitles': True,
        'writeautomaticsub': True,
        'subtitleslangs': ['zh-Hans', 'zh-CN', 'zh', 'zh-TW', 'en'],
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)

        meta = extract_video_meta(info)
        title = meta.get('title') or 'æœªçŸ¥æ ‡é¢˜'

        # ä¼˜å…ˆç”¨æ‰‹åŠ¨å­—å¹•ï¼Œå…¶æ¬¡è‡ªåŠ¨å­—å¹•
        subs = info.get('subtitles', {})
        auto_subs = info.get('automatic_captions', {})

        # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å­—å¹•
        lang_priority = ['zh-Hans', 'zh-CN', 'zh', 'zh-TW', 'en']
        chosen_subs = None
        source_type = None
        chosen_lang = None

        for lang in lang_priority:
            if lang in subs:
                chosen_subs = subs[lang]
                source_type = "official"
                chosen_lang = lang
                break

        if chosen_subs is None:
            for lang in lang_priority:
                if lang in auto_subs:
                    chosen_subs = auto_subs[lang]
                    source_type = "auto"
                    chosen_lang = lang
                    break

        if chosen_subs is None:
            return None, None, meta

        # é€‰æ‹© json3 æˆ– srv1 æ ¼å¼ä»¥è·å–æ—¶é—´æˆ³
        sub_url = None
        for fmt in chosen_subs:
            if fmt.get('ext') == 'json3':
                sub_url = fmt['url']
                break
        if sub_url is None:
            for fmt in chosen_subs:
                if fmt.get('ext') in ('srv1', 'vtt', 'srv2'):
                    sub_url = fmt['url']
                    break

        if sub_url is None:
            return None, None, meta

        # ä¸‹è½½å¹¶è§£æå­—å¹•
        import urllib.request
        req = urllib.request.Request(sub_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=15) as resp:
            raw = resp.read().decode('utf-8')

        # å°è¯• json3 æ ¼å¼è§£æ
        segments = []
        try:
            data = json.loads(raw)
            events = data.get('events', [])
            for ev in events:
                segs = ev.get('segs', [])
                text = ''.join(s.get('utf8', '') for s in segs).strip()
                if not text or text == '\n':
                    continue
                start_ms = ev.get('tStartMs', 0)
                dur_ms = ev.get('dDurationMs', 0)
                segments.append({
                    'start': start_ms / 1000.0,
                    'end': (start_ms + dur_ms) / 1000.0,
                    'text': text
                })
        except (json.JSONDecodeError, KeyError):
            # å°è¯•ç”¨ VTT/SRT æ ¼å¼è§£æ
            segments = parse_vtt_subtitles(raw)

        if segments:
            return segments, source_type, meta

        return None, None, meta

    except Exception as e:
        logger.error(f"[å­—å¹•æå–] é”™è¯¯: {e}")
        return None, None, {'title': 'æœªçŸ¥æ ‡é¢˜', 'uploader': '', 'upload_date': '', 'thumbnail': ''}


def parse_vtt_subtitles(raw_text):
    """ç®€å•è§£æ VTT æ ¼å¼å­—å¹•"""
    import re
    segments = []
    # åŒ¹é…æ—¶é—´è¡Œ: 00:00:01.000 --> 00:00:04.000
    pattern = re.compile(
        r'(\d{2}):(\d{2}):(\d{2})[.,](\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2})[.,](\d{3})'
    )
    lines = raw_text.split('\n')
    i = 0
    while i < len(lines):
        match = pattern.search(lines[i])
        if match:
            h1, m1, s1, ms1, h2, m2, s2, ms2 = match.groups()
            start = int(h1)*3600 + int(m1)*60 + int(s1) + int(ms1)/1000
            end = int(h2)*3600 + int(m2)*60 + int(s2) + int(ms2)/1000
            i += 1
            text_lines = []
            while i < len(lines) and lines[i].strip():
                text_lines.append(lines[i].strip())
                i += 1
            text = ' '.join(text_lines)
            # å»é™¤ VTT æ ‡ç­¾
            text = re.sub(r'<[^>]+>', '', text)
            if text:
                segments.append({'start': start, 'end': end, 'text': text})
        i += 1
    return segments


def download_and_transcribe(url, audio_path, task=None):
    """ä¸‹è½½éŸ³é¢‘å¹¶ç”¨ Whisper è½¬å½•"""
    import mlx_whisper
    import tqdm as tqdm_module
    import glob

    # audio_path åº”è¯¥æ˜¯ä¸å¸¦æ‰©å±•åçš„ stemï¼Œå¦‚ "temp_xxx"
    # å»æ‰å¯èƒ½å­˜åœ¨çš„æ‰©å±•å
    audio_stem = os.path.splitext(audio_path)[0]

    # ä¸‹è½½
    if task:
        task['status'] = 'downloading'
        task['message'] = 'â¬‡ï¸ æ­£åœ¨ä¸‹è½½éŸ³é¢‘...'

    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': audio_stem + '.%(ext)s',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'm4a',
        }],
        'quiet': True,
        'no_warnings': True,
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

    # yt-dlp åå¤„ç†å™¨è½¬ç åï¼Œå®é™…æ–‡ä»¶åå¯èƒ½æ˜¯ stem.m4a
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å®é™…ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
    actual_audio = None
    for ext in ['m4a', 'mp3', 'wav', 'ogg', 'opus', 'webm', 'mp4']:
        candidate = f"{audio_stem}.{ext}"
        if os.path.exists(candidate):
            actual_audio = candidate
            break
    # å…œåº•ï¼šç”¨ glob åŒ¹é…
    if not actual_audio:
        candidates = glob.glob(f"{audio_stem}.*")
        if candidates:
            actual_audio = candidates[0]

    if not actual_audio or not os.path.exists(actual_audio):
        raise FileNotFoundError(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {audio_stem}.*")

    logger.info(f"[è½¬å½•] éŸ³é¢‘æ–‡ä»¶: {actual_audio} ({os.path.getsize(actual_audio)} bytes)")

    if task:
        task['status'] = 'transcribing'
        task['message'] = 'ğŸ§  æ­£åœ¨ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è½¬å½•...'
        task['progress'] = 'æ¨¡å‹åŠ è½½ä¸­...'

    # â”€â”€ Monkey-patch tqdm ä»¥æ•è·è½¬å½•è¿›åº¦ â”€â”€
    _original_tqdm = tqdm_module.tqdm

    class _ProgressTqdm(_original_tqdm):
        def update(self, n=1):
            super().update(n)
            if task and self.total and self.total > 0:
                pct = min(self.n / self.total * 100, 100)
                task['transcribe_percent'] = round(pct, 1)
                task['transcribe_current'] = self.n
                task['transcribe_total'] = self.total
                task['progress'] = f'è½¬å½•ä¸­ {pct:.0f}%'

    tqdm_module.tqdm = _ProgressTqdm
    try:
        # è½¬å½•ï¼ˆverbose=False å¯ç”¨ tqdmï¼‰
        result = mlx_whisper.transcribe(
            actual_audio,
            path_or_hf_repo="mlx-community/whisper-large-v3-turbo",
            verbose=False,
            language="zh"
        )
    finally:
        tqdm_module.tqdm = _original_tqdm

    segments = result.get('segments', [])

    # æ›´æ–°å·²è½¬å½•çš„ segments åˆ° task
    if task:
        task['segments'] = [{'start': s['start'], 'end': s.get('end', 0), 'text': s['text'].strip()} for s in segments]
        task['progress'] = f'è½¬å½•å®Œæˆï¼Œå…± {len(segments)} æ®µ'
        task['transcribe_percent'] = 100

    # æ¸…ç†
    if os.path.exists(actual_audio):
        os.remove(actual_audio)

    return segments


def build_timestamped_transcript(segments):
    """å°† segments è½¬æ¢ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬"""
    lines = []
    for seg in segments:
        ts = format_timestamp(seg['start'])
        lines.append(f"[{ts}] {seg['text'].strip()}")
    return "\n".join(lines)


def get_summary_prompt(timestamped_transcript, title='', uploader='', upload_date=''):
    """ç”Ÿæˆæ€»ç»“ promptï¼ˆä» prompts.json è¯»å–æ¨¡æ¿ï¼‰"""
    prompts = load_prompts()
    template = prompts.get('summary_prompt', '')
    if not template:
        logger.warning('prompts.json ä¸­æœªæ‰¾åˆ° summary_promptï¼Œä½¿ç”¨å†…ç½®é»˜è®¤')
        template = 'è¯·æ€»ç»“ä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œä½¿ç”¨ä¸­æ–‡ Markdown æ ¼å¼ï¼š\n\n{transcript}'
    return (template
            .replace('{transcript}', timestamped_transcript)
            .replace('{title}', title or 'æœªçŸ¥æ ‡é¢˜')
            .replace('{uploader}', uploader or 'æœªçŸ¥ä½œè€…')
            .replace('{upload_date}', upload_date or 'æœªçŸ¥æ—¥æœŸ'))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åå°å¤„ç†ä»»åŠ¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_video_task(task_id, url):
    """åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†æ•´ä¸ªæµç¨‹"""
    task = tasks[task_id]

    try:
        # æ­¥éª¤ 0: è§„èŒƒåŒ– URL
        url = normalize_url(url)
        task['video_url'] = url
        logger.info(f"[ä»»åŠ¡ {task_id}] è§„èŒƒåŒ– URL: {url}")

        # æ­¥éª¤ 1: æ£€æµ‹å®˜æ–¹å­—å¹•
        task['status'] = 'checking_subtitles'
        task['message'] = 'ğŸ” æ­£åœ¨æ£€æµ‹è§†é¢‘æ˜¯å¦æœ‰å®˜æ–¹å­—å¹•...'
        segments, sub_source, meta = extract_official_subtitles(url)
        if not isinstance(meta, dict):
            meta = {'title': 'æœªçŸ¥æ ‡é¢˜', 'uploader': '', 'upload_date': '', 'thumbnail': ''}

        task['title'] = meta.get('title') or 'æœªçŸ¥æ ‡é¢˜'
        task['uploader'] = meta.get('uploader', '')
        task['upload_date'] = meta.get('upload_date', '')
        task['thumbnail'] = meta.get('thumbnail', '')
        task['uploader_url'] = meta.get('uploader_url', '')
        task['uploader_avatar'] = meta.get('uploader_avatar', '')

        if segments and len(segments) > 0:
            task['subtitle_source'] = 'official' if sub_source == 'official' else 'auto_generated'
            task['message'] = f'âœ… æ£€æµ‹åˆ°{"å®˜æ–¹" if sub_source == "official" else "è‡ªåŠ¨ç”Ÿæˆ"}å­—å¹•ï¼Œæ— éœ€è½¬å½•ï¼'
        else:
            # æ­¥éª¤ 2: éœ€è¦ä¸‹è½½å¹¶è½¬å½•
            task['subtitle_source'] = 'whisper'
            audio_path = f"temp_{task_id}.m4a"
            # åŠ é”ï¼šMLX Metal GPU ä¸æ”¯æŒå¹¶å‘è½¬å½•
            if transcribe_lock.locked():
                task['message'] = 'â³ ç­‰å¾…å…¶ä»–è½¬å½•ä»»åŠ¡å®Œæˆ...'
            with transcribe_lock:
                segments = download_and_transcribe(url, audio_path, task=task)
            task['message'] = 'âœ… è½¬å½•å®Œæˆï¼'

        # æ­¥éª¤ 3: æ„å»ºå¸¦æ—¶é—´æˆ³çš„å­—å¹•
        task['status'] = 'summarizing'
        task['message'] = 'ğŸ¤– æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆæ€»ç»“...'
        # ä¿å­˜ segments åŸå§‹æ•°æ®ä¾›å‰ç«¯ä½¿ç”¨
        task['segments'] = [{'start': s['start'], 'end': s.get('end', 0), 'text': s['text'].strip()} for s in segments]
        timestamped_transcript = build_timestamped_transcript(segments)
        task['transcript'] = timestamped_transcript

        # æ­¥éª¤ 4: AI æ€»ç»“
        prompt = get_summary_prompt(
            timestamped_transcript,
            title=task.get('title', ''),
            uploader=task.get('uploader', ''),
            upload_date=task.get('upload_date', '')
        )
        response = generate_content_with_fallback(prompt, model=MODEL_ID)
        task['summary'] = response.text

        # æ­¥éª¤ 5: AI è‡ªåŠ¨åˆ†ç±»æ ‡ç­¾
        task['tag'] = ''
        try:
            tags = load_tags()
            if tags:
                prompts = load_prompts()
                classify_template = prompts.get('classify_prompt', '')
                if classify_template:
                    classify_prompt = (classify_template
                        .replace('{title}', task.get('title', ''))
                        .replace('{tags}', 'ã€'.join(tags)))
                    classify_resp = generate_content_with_fallback(classify_prompt, model=MODEL_ID)
                    chosen_tag = classify_resp.text.strip().strip('"').strip("'").strip()
                    # éªŒè¯è¿”å›çš„æ ‡ç­¾åœ¨åˆ—è¡¨ä¸­
                    if chosen_tag in tags:
                        task['tag'] = chosen_tag
                        logger.info(f"[ä»»åŠ¡ {task_id}] AI åˆ†ç±»æ ‡ç­¾: {chosen_tag}")
                    else:
                        logger.warning(f"[ä»»åŠ¡ {task_id}] AI è¿”å›æ ‡ç­¾ '{chosen_tag}' ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œè·³è¿‡")
        except Exception as e:
            logger.warning(f"[ä»»åŠ¡ {task_id}] è‡ªåŠ¨åˆ†ç±»å¤±è´¥: {e}")

        # å®Œæˆ
        task['status'] = 'done'
        task['message'] = 'ğŸ‰ å¤„ç†å®Œæˆï¼'

        # æŒä¹…åŒ–ä¿å­˜é¡¹ç›®
        save_project(task_id, {
            'id': task_id,
            'title': task.get('title', 'æœªçŸ¥æ ‡é¢˜'),
            'video_url': task.get('video_url', ''),
            'uploader': task.get('uploader', ''),
            'upload_date': task.get('upload_date', ''),
            'thumbnail': task.get('thumbnail', ''),
            'uploader_url': task.get('uploader_url', ''),
            'uploader_avatar': task.get('uploader_avatar', ''),
            'subtitle_source': task.get('subtitle_source', ''),
            'transcript': task.get('transcript', ''),
            'segments': task.get('segments', []),
            'summary': task.get('summary', ''),
            'tag': task.get('tag', ''),
            'created_at': _now_iso(),
            'chat_history': [],
            'status': 'done',
            'message': task.get('message', ''),
            'progress': task.get('progress', ''),
            'transcribe_percent': task.get('transcribe_percent', 0),
        })

    except Exception as e:
        task['status'] = 'error'
        task['message'] = f'âŒ å¤„ç†å¤±è´¥: {str(e)}'
        logger.error(f"[ä»»åŠ¡ {task_id}] é”™è¯¯: {e}", exc_info=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API è·¯ç”±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route('/')
def index():
    return send_from_directory('static', 'index.html')


@app.route('/api/process', methods=['POST'])
def start_process():
    """å¯åŠ¨è§†é¢‘å¤„ç†ä»»åŠ¡"""
    data = request.json
    raw = data.get('url', '').strip()

    if not raw:
        return jsonify({'error': 'è¯·è¾“å…¥è§†é¢‘é“¾æ¥'}), 400

    # åç«¯ä¹Ÿåšä¸€æ¬¡ URL æå–ï¼ˆé˜²æ­¢ç”¨æˆ·ç²˜è´´ "ã€æ ‡é¢˜ã€‘ https://..." æ··åˆæ–‡æœ¬ï¼‰
    url = _extract_first_url(raw)
    if not url:
        return jsonify({'error': 'æœªè¯†åˆ«åˆ°æœ‰æ•ˆè§†é¢‘é“¾æ¥ï¼Œè¯·ç²˜è´´å®Œæ•´ URL'}), 400

    # å…ˆè§„èŒƒåŒ– URLï¼Œé¿å…å ä½é¡¹ç›®é‡Œå‡ºç°ä¸å¸¦ www çš„ Bç«™é“¾æ¥ç­‰
    normalized_url = normalize_url(url)

    # å»é‡ï¼šåŒä¸€ä¸ªè§†é¢‘è‹¥å·²æœ‰è¿›è¡Œä¸­/æ’é˜Ÿä¸­çš„ä»»åŠ¡ï¼Œç›´æ¥å¤ç”¨
    running_status = {'queued', 'pending', 'checking_subtitles', 'downloading', 'transcribing', 'summarizing'}
    for exist_id, exist_task in tasks.items():
        if exist_task.get('video_url') == normalized_url and exist_task.get('status') in running_status:
            return jsonify({'task_id': exist_id, 'reused': True})

    task_id = str(uuid.uuid4())[:8]
    created_at = _now_iso()
    tasks[task_id] = {
        'status': 'queued',
        'message': 'ğŸ§¾ å·²å…¥é˜Ÿï¼Œç­‰å¾…å¤„ç†...',
        'title': '',
        'subtitle_source': '',
        'transcript': '',
        'segments': [],
        'summary': '',
        'video_url': normalized_url,
        'uploader': '',
        'upload_date': '',
        'thumbnail': '',
        'uploader_url': '',
        'uploader_avatar': '',
        'progress': '',
        'transcribe_percent': 0,
        'transcribe_current': 0,
        'transcribe_total': 0,
        'created_at': created_at,
    }

    # å…ˆå†™å…¥ä¸€ä¸ªâ€œè¿›è¡Œä¸­â€çš„é¡¹ç›®å ä½ï¼Œç¡®ä¿åˆ·æ–°é¡µé¢ä¹Ÿèƒ½çœ‹åˆ°
    # æœ€ç»ˆå®Œæˆåä¼šåœ¨ process_video_task ä¸­è¦†ç›–ä¸ºå®Œæ•´æ•°æ®
    save_project(task_id, {
        'id': task_id,
        'title': infer_title_from_url(normalized_url),
        'video_url': normalized_url,
        'uploader': '',
        'upload_date': '',
        'thumbnail': '',
        'uploader_url': '',
        'uploader_avatar': '',
        'subtitle_source': '',
        'transcript': '',
        'segments': [],
        'summary': '',
        'created_at': created_at,
        'status': 'queued',
        'message': 'ğŸ§¾ å·²å…¥é˜Ÿï¼Œç­‰å¾…å¤„ç†...',
        'progress': '',
        'transcribe_percent': 0,
        'chat_history': [],
    })

    task_queue.put((task_id, normalized_url))

    return jsonify({'task_id': task_id})


@app.route('/api/status/<task_id>')
def get_status(task_id):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task = tasks.get(task_id)
    if not task:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    return jsonify(task)


@app.route('/api/projects')
def list_projects():
    """è·å–æ‰€æœ‰å·²ä¿å­˜çš„é¡¹ç›®åˆ—è¡¨ï¼ˆä¸å«å®Œæ•´å†…å®¹ï¼Œåªå«æ‘˜è¦ï¼‰"""
    projects = load_projects()

    # å…ˆä»ç£ç›˜é¡¹ç›®ç”Ÿæˆåˆ—è¡¨
    by_id = {}
    for pid, p in projects.items():
        by_id[pid] = {
            'id': pid,
            'title': p.get('title', 'æœªçŸ¥æ ‡é¢˜') or 'æœªå‘½åé¡¹ç›®',
            'subtitle_source': p.get('subtitle_source', ''),
            'created_at': p.get('created_at', ''),
            'video_url': p.get('video_url', ''),
            'thumbnail': p.get('thumbnail', ''),
            'uploader': p.get('uploader', ''),
            'upload_date': p.get('upload_date', ''),
            'uploader_url': p.get('uploader_url', ''),
            'uploader_avatar': p.get('uploader_avatar', ''),
            'status': p.get('status', 'done'),
            'message': p.get('message', ''),
            'progress': p.get('progress', ''),
            'transcribe_percent': p.get('transcribe_percent', 0),
            'tag': p.get('tag', ''),
            'favorite': p.get('favorite', False),
        }

    # å†æŠŠå†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€åˆå¹¶è¿›å»ï¼ˆä¿è¯åˆ·æ–°é¡µé¢èƒ½çœ‹åˆ°è¿›è¡Œä¸­ä»»åŠ¡ï¼‰
    for tid, t in tasks.items():
        row = by_id.get(tid, {
            'id': tid,
            'title': 'æœªå‘½åé¡¹ç›®',
            'subtitle_source': '',
            'created_at': t.get('created_at', ''),
            'video_url': t.get('video_url', ''),
            'tag': '',
        })
        # ç”¨æœ€æ–°ä»»åŠ¡çŠ¶æ€è¦†ç›–
        row['title'] = t.get('title') or row.get('title') or 'æœªå‘½åé¡¹ç›®'
        row['subtitle_source'] = t.get('subtitle_source', row.get('subtitle_source', ''))
        row['created_at'] = t.get('created_at', row.get('created_at', ''))
        row['video_url'] = t.get('video_url', row.get('video_url', ''))
        row['thumbnail'] = t.get('thumbnail', row.get('thumbnail', ''))
        row['uploader'] = t.get('uploader', row.get('uploader', ''))
        row['upload_date'] = t.get('upload_date', row.get('upload_date', ''))
        row['uploader_url'] = t.get('uploader_url', row.get('uploader_url', ''))
        row['uploader_avatar'] = t.get('uploader_avatar', row.get('uploader_avatar', ''))
        row['status'] = t.get('status', row.get('status', ''))
        row['message'] = t.get('message', row.get('message', ''))
        row['progress'] = t.get('progress', row.get('progress', ''))
        row['transcribe_percent'] = t.get('transcribe_percent', row.get('transcribe_percent', 0))
        row['tag'] = t.get('tag', row.get('tag', ''))
        row['favorite'] = row.get('favorite', False)
        by_id[tid] = row

    project_list = list(by_id.values())
    project_list.sort(key=lambda x: x.get('created_at', ''), reverse=True)
    return jsonify(project_list)


@app.route('/api/projects/<project_id>')
def get_project(project_id):
    """è·å–å•ä¸ªé¡¹ç›®çš„å®Œæ•´æ•°æ®"""
    projects = load_projects()
    project = projects.get(project_id)
    task = tasks.get(project_id)

    if project is None and task is None:
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404

    # ä»¥ç£ç›˜æ•°æ®ä¸ºåŸºç¡€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå†ç”¨å†…å­˜ä»»åŠ¡è¦†ç›–æœ€æ–°çŠ¶æ€
    data = project.copy() if isinstance(project, dict) else {
        'id': project_id,
        'title': 'æœªå‘½åé¡¹ç›®',
        'video_url': '',
        'subtitle_source': '',
        'segments': [],
        'transcript': '',
        'summary': '',
        'created_at': '',
        'chat_history': [],
    }

    if task:
        data.update({
            'id': project_id,
            'title': task.get('title') or data.get('title', 'æœªå‘½åé¡¹ç›®'),
            'video_url': task.get('video_url') or data.get('video_url', ''),
            'uploader': task.get('uploader', data.get('uploader', '')),
            'upload_date': task.get('upload_date', data.get('upload_date', '')),
            'thumbnail': task.get('thumbnail', data.get('thumbnail', '')),
            'uploader_url': task.get('uploader_url', data.get('uploader_url', '')),
            'uploader_avatar': task.get('uploader_avatar', data.get('uploader_avatar', '')),
            'subtitle_source': task.get('subtitle_source') or data.get('subtitle_source', ''),
            'segments': task.get('segments', data.get('segments', [])),
            'transcript': task.get('transcript', data.get('transcript', '')),
            'summary': task.get('summary', data.get('summary', '')),
            'created_at': task.get('created_at') or data.get('created_at', ''),
            'status': task.get('status', data.get('status', '')),
            'message': task.get('message', data.get('message', '')),
            'progress': task.get('progress', data.get('progress', '')),
            'transcribe_percent': task.get('transcribe_percent', data.get('transcribe_percent', 0)),
            'transcribe_current': task.get('transcribe_current', data.get('transcribe_current', 0)),
            'transcribe_total': task.get('transcribe_total', data.get('transcribe_total', 0)),
            'tag': task.get('tag', data.get('tag', '')),
            'favorite': data.get('favorite', False),
        })
    else:
        data.setdefault('status', data.get('status', 'done'))
        data.setdefault('favorite', data.get('favorite', False))

    return jsonify(data)


@app.route('/api/projects/<project_id>/thumbnail')
def project_thumbnail(project_id):
    """å°é¢ä»£ç†æ¥å£ï¼šè§„é¿é˜²ç›—é“¾/CORSï¼Œè¿”å›é¡¹ç›®å°é¢å›¾ç‰‡ã€‚"""
    projects = load_projects()
    project = projects.get(project_id, {}) if isinstance(projects, dict) else {}
    task = tasks.get(project_id, {})

    thumb_url = ''
    video_url = ''
    if isinstance(project, dict):
        thumb_url = project.get('thumbnail', '') or thumb_url
        video_url = project.get('video_url', '') or video_url
    if isinstance(task, dict):
        thumb_url = task.get('thumbnail', '') or thumb_url
        video_url = task.get('video_url', '') or video_url

    if not thumb_url:
        return Response('thumbnail not found', status=404)

    os.makedirs(THUMB_CACHE_DIR, exist_ok=True)
    # å…ˆæ‰¾ç¼“å­˜
    for ext, ctype in [('jpg', 'image/jpeg'), ('png', 'image/png'), ('webp', 'image/webp'), ('gif', 'image/gif')]:
        cached = _thumbnail_cache_path(thumb_url, ext)
        if os.path.exists(cached):
            with open(cached, 'rb') as f:
                return Response(f.read(), mimetype=ctype, headers={'Cache-Control': 'public, max-age=86400'})

    # ä¸‹è½½å¹¶ç¼“å­˜
    try:
        data, ctype = _download_thumbnail(thumb_url, referer=video_url)
        ext = _ext_from_content_type(ctype)
        cache_path = _thumbnail_cache_path(thumb_url, ext)
        with open(cache_path, 'wb') as f:
            f.write(data)
        return Response(data, mimetype=ctype, headers={'Cache-Control': 'public, max-age=86400'})
    except Exception as e:
        logger.warning(f"[å°é¢ä»£ç†] ä¸‹è½½å¤±è´¥: {e}")
        return Response('thumbnail fetch failed', status=502)


@app.route('/api/projects/<project_id>/avatar')
def project_avatar(project_id):
    """ä½œè€…å¤´åƒä»£ç†æ¥å£ï¼ˆåŒå°é¢ä»£ç†é€»è¾‘ï¼‰ã€‚"""
    projects = load_projects()
    project = projects.get(project_id, {}) if isinstance(projects, dict) else {}
    task = tasks.get(project_id, {})

    avatar_url = ''
    video_url = ''
    if isinstance(project, dict):
        avatar_url = project.get('uploader_avatar', '') or avatar_url
        video_url = project.get('video_url', '') or video_url
    if isinstance(task, dict):
        avatar_url = task.get('uploader_avatar', '') or avatar_url
        video_url = task.get('video_url', '') or video_url

    if not avatar_url:
        return Response('avatar not found', status=404)

    os.makedirs(THUMB_CACHE_DIR, exist_ok=True)
    for ext, ctype in [('jpg', 'image/jpeg'), ('png', 'image/png'), ('webp', 'image/webp')]:
        cached = _thumbnail_cache_path(avatar_url, ext)
        if os.path.exists(cached):
            with open(cached, 'rb') as f:
                return Response(f.read(), mimetype=ctype, headers={'Cache-Control': 'public, max-age=86400'})

    try:
        data, ctype = _download_thumbnail(avatar_url, referer=video_url)
        ext = _ext_from_content_type(ctype)
        cache_path = _thumbnail_cache_path(avatar_url, ext)
        with open(cache_path, 'wb') as f:
            f.write(data)
        return Response(data, mimetype=ctype, headers={'Cache-Control': 'public, max-age=86400'})
    except Exception as e:
        logger.warning(f"[å¤´åƒä»£ç†] ä¸‹è½½å¤±è´¥: {e}")
        return Response('avatar fetch failed', status=502)


@app.route('/favicon.ico')
def favicon():
    """SVG favicon"""
    svg = '''<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100">
<rect width="100" height="100" rx="20" fill="#6366f1"/>
<text x="50" y="72" text-anchor="middle" font-size="60" fill="white">ğŸ“º</text>
</svg>'''
    return Response(svg, mimetype='image/svg+xml', headers={'Cache-Control': 'public, max-age=604800'})


@app.route('/api/projects/<project_id>', methods=['DELETE'])
def delete_project(project_id):
    """åˆ é™¤é¡¹ç›®"""
    projects = load_projects()
    if project_id in projects:
        del projects[project_id]
        save_projects(projects)
        # åŒæ—¶æ¸…ç†èŠå¤©å†å²
        session_key = f'session_{project_id}'
        if session_key in chat_sessions:
            del chat_sessions[session_key]
        return jsonify({'ok': True})
    return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404


@app.route('/api/projects/<project_id>', methods=['PATCH'])
def update_project(project_id):
    """æ›´æ–°é¡¹ç›®å±æ€§ï¼ˆæ ‡é¢˜ã€æ ‡ç­¾ç­‰ï¼‰"""
    projects = load_projects()
    project = projects.get(project_id)
    if project is None:
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404

    data = request.json or {}
    updated = False

    if 'title' in data:
        new_title = str(data['title']).strip()
        if new_title:
            project['title'] = new_title
            updated = True

    if 'tag' in data:
        project['tag'] = str(data['tag']).strip()
        updated = True

    if 'favorite' in data:
        project['favorite'] = bool(data['favorite'])
        updated = True

    if updated:
        save_projects(projects)
    return jsonify({'ok': True, 'title': project.get('title', ''), 'tag': project.get('tag', ''), 'favorite': project.get('favorite', False)})


# â”€â”€ æ ‡ç­¾ç®¡ç† â”€â”€

@app.route('/api/tags')
def get_tags():
    """è·å–æ‰€æœ‰æ ‡ç­¾"""
    return jsonify(load_tags())


@app.route('/api/tags', methods=['POST'])
def add_tag():
    """æ–°å¢æ ‡ç­¾"""
    data = request.json or {}
    name = str(data.get('name', '')).strip()
    if not name:
        return jsonify({'error': 'æ ‡ç­¾åä¸èƒ½ä¸ºç©º'}), 400
    tags = load_tags()
    if name in tags:
        return jsonify({'error': 'æ ‡ç­¾å·²å­˜åœ¨'}), 400
    tags.append(name)
    save_tags(tags)
    return jsonify({'ok': True, 'tags': tags})


@app.route('/api/tags', methods=['DELETE'])
def delete_tag():
    """åˆ é™¤æ ‡ç­¾"""
    data = request.json or {}
    name = str(data.get('name', '')).strip()
    if not name:
        return jsonify({'error': 'æ ‡ç­¾åä¸èƒ½ä¸ºç©º'}), 400
    tags = load_tags()
    if name not in tags:
        return jsonify({'error': 'æ ‡ç­¾ä¸å­˜åœ¨'}), 404
    tags.remove(name)
    save_tags(tags)
    return jsonify({'ok': True, 'tags': tags})


@app.route('/api/classify-all', methods=['POST'])
def classify_all_projects():
    """å¯¹æ‰€æœ‰æ²¡æœ‰æ ‡ç­¾çš„é¡¹ç›®è¿›è¡Œ AI åˆ†ç±»"""
    projects = load_projects()
    tags = load_tags()
    prompts = load_prompts()
    classify_template = prompts.get('classify_prompt', '')

    if not tags or not classify_template:
        return jsonify({'error': 'ç¼ºå°‘æ ‡ç­¾åˆ—è¡¨æˆ–åˆ†ç±» prompt æ¨¡æ¿'}), 400

    classified = 0
    failed = 0
    for pid, p in projects.items():
        if p.get('tag') or p.get('status') != 'done':
            continue  # è·³è¿‡å·²æœ‰æ ‡ç­¾æˆ–æœªå®Œæˆçš„é¡¹ç›®
        title = p.get('title', '')
        if not title or title == 'æœªå‘½åé¡¹ç›®':
            continue
        try:
            prompt = (classify_template
                      .replace('{title}', title)
                      .replace('{tags}', 'ã€'.join(tags)))
            resp = generate_content_with_fallback(prompt, model=MODEL_ID)
            chosen = resp.text.strip().strip('"').strip("'").strip()
            if chosen in tags:
                p['tag'] = chosen
                classified += 1
                logger.info(f'[æ‰¹é‡åˆ†ç±»] {pid} "{title}" â†’ {chosen}')
            else:
                logger.warning(f'[æ‰¹é‡åˆ†ç±»] {pid} AI è¿”å› "{chosen}" ä¸åœ¨æ ‡ç­¾åˆ—è¡¨ä¸­')
                failed += 1
        except Exception as e:
            logger.warning(f'[æ‰¹é‡åˆ†ç±»] {pid} åˆ†ç±»å¤±è´¥: {e}')
            failed += 1

    save_projects(projects)
    return jsonify({'ok': True, 'classified': classified, 'failed': failed})


@app.route('/api/chat', methods=['POST'])
def chat():
    """å¤šè½®å¯¹è¯æ¥å£"""
    data = request.json
    session_id = data.get('session_id', '')
    user_message = data.get('message', '').strip()
    transcript = data.get('transcript', '')

    if not user_message:
        return jsonify({'error': 'è¯·è¾“å…¥æ¶ˆæ¯'}), 400

    # åˆå§‹åŒ–æˆ–è·å–èŠå¤©å†å²
    if session_id not in chat_sessions:
        # å¦‚æœæ˜¯å·²ä¿å­˜é¡¹ç›®ï¼ŒåŠ è½½å…¶å†å²
        project_id = _project_id_from_session_id(session_id)
        projects = load_projects() if project_id else {}
        persisted = projects.get(project_id) if project_id else None
        persisted_history = (persisted or {}).get('chat_history', [])

        chat_sessions[session_id] = {
            'history': persisted_history[:] if isinstance(persisted_history, list) else [],
            'transcript': transcript
        }
        # å°†å­—å¹•ä½œä¸ºç³»ç»Ÿä¸Šä¸‹æ–‡ï¼ˆä» prompts.json è¯»å–æ¨¡æ¿ï¼‰
        prompts = load_prompts()
        chat_template = prompts.get('chat_system_prompt', '')
        if not chat_template:
            logger.warning('prompts.json ä¸­æœªæ‰¾åˆ° chat_system_promptï¼Œä½¿ç”¨å†…ç½®é»˜è®¤')
            chat_template = 'ä½ æ˜¯ä¸€ä½è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯è§†é¢‘å­—å¹•ï¼š\n\n---\n{transcript}\n---\n\nè¯·åŸºäºå­—å¹•å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚'
        system_context = chat_template.replace('{transcript}', transcript)

        chat_sessions[session_id]['system_context'] = system_context

    session = chat_sessions[session_id]

    # æ„å»ºå¯¹è¯å†…å®¹
    contents = [session['system_context']]
    for msg in session['history']:
        # å…¼å®¹æ—§æ ¼å¼ï¼šå¯èƒ½æ˜¯ dict æˆ– str
        if isinstance(msg, dict):
            role = msg.get('role', '')
            content = msg.get('content', '')
            if role == 'user':
                contents.append(f"ç”¨æˆ·ï¼š{content}")
            elif role == 'assistant':
                contents.append(f"åŠ©æ‰‹ï¼š{content}")
            else:
                contents.append(content)
        else:
            contents.append(str(msg))

    contents.append(f"ç”¨æˆ·ï¼š{user_message}")

    try:
        response = generate_content_with_fallback(contents, model=MODEL_ID)
        reply = response.text

        # ä¿å­˜å¯¹è¯å†å²
        session['history'].append({'role': 'user', 'content': user_message})
        session['history'].append({'role': 'assistant', 'content': reply})

        # æŒä¹…åŒ–å†™å›é¡¹ç›®ï¼ˆç”¨äºåˆ·æ–°åç»§ç»­è¿½é—®+å›çœ‹å†å²ï¼‰
        project_id = _project_id_from_session_id(session_id)
        if project_id:
            projects = load_projects()
            project = projects.get(project_id)
            if project is not None:
                project.setdefault('chat_history', [])
                project['chat_history'] = session['history']
                save_projects(projects)

        return jsonify({'reply': reply})

    except Exception as e:
        return jsonify({'error': f'AI å›å¤å¤±è´¥: {str(e)}'}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¯åŠ¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == '__main__':
    os.makedirs('static', exist_ok=True)
    print("\n" + "=" * 50)
    print("ğŸš€ è§†é¢‘å­—å¹•æå– & AI æ€»ç»“ Web åº”ç”¨")
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:5003")
    print("=" * 50 + "\n")
    app.run(host='0.0.0.0', port=5003, debug=True)
